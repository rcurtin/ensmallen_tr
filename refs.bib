@ARTICLE{2019arXiv190710121V,
       author = {{Virtanen}, Pauli and {Gommers}, Ralf and {Oliphant},
         Travis E. and {Haberland}, Matt and {Reddy}, Tyler and
         {Cournapeau}, David and {Burovski}, Evgeni and {Peterson}, Pearu
         and {Weckesser}, Warren and {Bright}, Jonathan and {van der Walt},
         St{\'e}fan J.  and {Brett}, Matthew and {Wilson}, Joshua and
         {Jarrod Millman}, K.  and {Mayorov}, Nikolay and {Nelson}, Andrew
         R.~J. and {Jones}, Eric and {Kern}, Robert and {Larson}, Eric and
         {Carey}, CJ and {Polat}, {\.I}lhan and {Feng}, Yu and {Moore},
         Eric W. and {Vand erPlas}, Jake and {Laxalde}, Denis and
         {Perktold}, Josef and {Cimrman}, Robert and {Henriksen}, Ian and
         {Quintero}, E.~A. and {Harris}, Charles R and {Archibald}, Anne M.
         and {Ribeiro}, Ant{\^o}nio H. and {Pedregosa}, Fabian and
         {van Mulbregt}, Paul and {Contributors}, SciPy 1. 0},
        title = "{SciPy 1.0--Fundamental Algorithms for Scientific
                  Computing in Python}",
      journal = {arXiv e-prints},
         year = "2019",
        month = "Jul",
          eid = {arXiv:1907.10121},
        pages = {arXiv:1907.10121},
archivePrefix = {arXiv},
       eprint = {1907.10121},
 primaryClass = {cs.MS},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2019arXiv190710121V},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@techreport{meza1994opt++,
  title={OPT++: An object-oriented class library for nonlinear optimization},
  author={Meza, Juan C.},
  year={1994},
  institution={Sandia National Labs., Livermore, CA (United States)}
}

@software{ortools,
  title = {OR-Tools},
  version = {7.2},
  author = {Laurent Perron and Vincent Furnon},
  organization = {Google},
  url = {https://developers.google.com/optimization/},
  date = {2019-7-19}
}

@article{vandenberghe2010cvxopt,
  title={The CVXOPT linear and quadratic cone program solvers},
  author={Vandenberghe, Lieven},
  journal={Online: http://cvxopt. org/documentation/coneprog. pdf},
  year={2010}
}

@software{johnson2014nlopt,
  title={The NLopt nonlinear-optimization package},
  author={Johnson, Steven G.},
  url={https://github.com/stevengj/nlopt}
}

@misc{ceres-solver,
  author = "Sameer Agarwal and Keir Mierle and Others",
  title = "Ceres Solver",
  howpublished = "\url{http://ceres-solver.org}",
}

@article{costa2018rbfopt,
  title={{RBFOpt}: an open-source library for black-box optimization with costly function evaluations},
  author={Costa, Alberto and Nannicini, Giacomo},
  journal={Mathematical Programming Computation},
  volume={10},
  number={4},
  pages={597--629},
  year={2018},
  publisher={Springer}
}


@ARTICLE{2016arXiv160502688full,
   author = {
     Rami Al-Rfou and
     Guillaume Alain and
     Amjad Almahairi and
     Christof Angermueller and
     Dzmitry Bahdanau and
     Nicolas Ballas and
     Fr\'ed\'eric Bastien and
     Justin Bayer and
     Anatoly Belikov and
     Alexander Belopolsky and
     Yoshua Bengio and
     Arnaud Bergeron and
     James Bergstra and
     Valentin Bisson and
     Josh {Bleecher Snyder} and
     Nicolas Bouchard and
     Nicolas Boulanger-Lewandowski and
     Xavier Bouthillier and
     Alexandre de Br\'ebisson and
     Olivier Breuleux and
     Pierre-Luc Carrier and
     Kyunghyun Cho and
     Jan Chorowski and
     Paul Christiano and
     Tim Cooijmans and
     Marc-Alexandre C\^ot\'e and
     Myriam C\^ot\'e and
     Aaron Courville and
     Yann N. Dauphin and
     Olivier Delalleau and
     Julien Demouth and
     Guillaume Desjardins and
     Sander Dieleman and
     Laurent Dinh and
     M\'elanie Ducoffe and
     Vincent Dumoulin and
     Samira {Ebrahimi Kahou} and
     Dumitru Erhan and
     Ziye Fan and
     Orhan Firat and
     Mathieu Germain and
     Xavier Glorot and
     Ian Goodfellow and
     Matt Graham and
     Caglar Gulcehre and
     Philippe Hamel and
     Iban Harlouchet and
     Jean-Philippe Heng and
     Bal\'azs Hidasi and
     Sina Honari and
     Arjun Jain and
     S\'ebastien Jean and
     Kai Jia and
     Mikhail Korobov and
     Vivek Kulkarni and
     Alex Lamb and
     Pascal Lamblin and
     Eric Larsen and
     C\'esar Laurent and
     Sean Lee and
     Simon Lefrancois and
     Simon Lemieux and
     Nicholas L\'eonard and
     Zhouhan Lin and
     Jesse A. Livezey and
     Cory Lorenz and
     Jeremiah Lowin and
     Qianli Ma and
     Pierre-Antoine Manzagol and
     Olivier Mastropietro and
     Robert T. McGibbon and
     Roland Memisevic and
     Bart van Merri\"enboer and
     Vincent Michalski and
     Mehdi Mirza and
     Alberto Orlandi and
     Christopher Pal and
     Razvan Pascanu and
     Mohammad Pezeshki and
     Colin Raffel and
     Daniel Renshaw and
     Matthew Rocklin and
     Adriana Romero and
     Markus Roth and
     Peter Sadowski and
     John Salvatier and
     Fran\c{c}ois Savard and
     Jan Schl\"uter and
     John Schulman and
     Gabriel Schwartz and
     Iulian Vlad Serban and
     Dmitriy Serdyuk and
     Samira Shabanian and
     \'Etienne Simon and
     Sigurd Spieckermann and
     S. Ramana Subramanyam and
     Jakub Sygnowski and
     J\'er\'emie Tanguay and
     Gijs van Tulder and
     Joseph Turian and
     Sebastian Urban and
     Pascal Vincent and
     Francesco Visin and
     Harm de Vries and
     David Warde-Farley and
     Dustin J. Webb and
     Matthew Willson and
     Kelvin Xu and
     Lijun Xue and
     Li Yao and
     Saizheng Zhang and
     Ying Zhang},
 collaboration = {Theano Development Team},
    title = "{Theano: A {Python} framework for fast computation of mathematical expressions}",
  journal = {arXiv e-prints},
   volume = {abs/1605.02688},
 primaryClass = "cs.SC",
 keywords = {Computer Science - Symbolic Computation, Computer Science - Learning, Computer Science - Mathematical Software},
     year = 2016,
    month = may,
      url = {http://arxiv.org/abs/1605.02688},
}

@misc{tensorflow2015-whitepaper,
title={ {TensorFlow}: Large-Scale Machine Learning on Heterogeneous Systems},
url={https://www.tensorflow.org/},
note={Software available from tensorflow.org},
author={
    Mart\'{\i}n~Abadi and
    Ashish~Agarwal and
    Paul~Barham and
    Eugene~Brevdo and
    Zhifeng~Chen and
    Craig~Citro and
    Greg~S.~Corrado and
    Andy~Davis and
    Jeffrey~Dean and
    Matthieu~Devin and
    Sanjay~Ghemawat and
    Ian~Goodfellow and
    Andrew~Harp and
    Geoffrey~Irving and
    Michael~Isard and
    Yangqing Jia and
    Rafal~Jozefowicz and
    Lukasz~Kaiser and
    Manjunath~Kudlur and
    Josh~Levenberg and
    Dandelion~Man\'{e} and
    Rajat~Monga and
    Sherry~Moore and
    Derek~Murray and
    Chris~Olah and
    Mike~Schuster and
    Jonathon~Shlens and
    Benoit~Steiner and
    Ilya~Sutskever and
    Kunal~Talwar and
    Paul~Tucker and
    Vincent~Vanhoucke and
    Vijay~Vasudevan and
    Fernanda~Vi\'{e}gas and
    Oriol~Vinyals and
    Pete~Warden and
    Martin~Wattenberg and
    Martin~Wicke and
    Yuan~Yu and
    Xiaoqiang~Zheng},
  year={2015},
}

@incollection{NEURIPS2019_9015,
title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
pages = {8024--8035},
year = {2019},
publisher = {Curran Associates, Inc.},
url = {http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf}
}

@article{jia2014caffe,
  Author = {Jia, Yangqing and Shelhamer, Evan and Donahue, Jeff and Karayev, Sergey and Long, Jonathan and Girshick, Ross and Guadarrama, Sergio and Darrell, Trevor},
  Journal = {arXiv preprint arXiv:1408.5093},
  Title = {Caffe: Convolutional Architecture for Fast Feature Embedding},
  Year = {2014}
}

@inproceedings{krizhevsky2012imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  booktitle={Advances in neural information processing systems},
  pages={1097--1105},
  year={2012}
}

@inproceedings{lauzon2012introduction,
  title={An introduction to deep learning},
  author={Lauzon, Francis Quintal},
  booktitle={2012 11th International Conference on Information Science, Signal Processing and their Applications (ISSPA)},
  pages={1438--1439},
  year={2012},
  organization={IEEE}
}

@article{dueri2016customized,
  title={Customized real-time interior-point methods for onboard powered-descent guidance},
  author={Dueri, Daniel and A{\c{c}}{\i}kme{\c{s}}e, Beh{\c{c}}et and Scharf, Daniel P and Harris, Matthew W},
  journal={Journal of Guidance, Control, and Dynamics},
  volume={40},
  number={2},
  pages={197--212},
  year={2016},
  publisher={American Institute of Aeronautics and Astronautics}
}

@article{manogaran2018health,
  title={Health data analytics using scalable logistic regression with stochastic gradient descent},
  author={Manogaran, Gunasekaran and Lopez, Daphne},
  journal={International Journal of Advanced Intelligence Paradigms},
  volume={10},
  number={1-2},
  pages={118--132},
  year={2018},
  publisher={Inderscience Publishers (IEL)}
}

@inproceedings{zhang2004solving,
  title={Solving large scale linear prediction problems using stochastic gradient descent algorithms},
  author={Zhang, Tong},
  booktitle={Proceedings of the Twenty-First International Conference on Machine Learning (ICML '04)},
  pages={116},
  year={2004},
  organization={ACM}
}

@software{matlab_fminsearch,
  title={{\tt fminsearch}},
  author={MathWorks},
  url={https://www.mathworks.com/help/matlab/ref/fminsearch.html},
  version={R2019b},
  year=2019
}

@inproceedings{ensmallen2018,
  title     = {ensmallen: a flexible {C}++ library for efficient function
               optimization},
  author    = {Bhardwaj, Shikhar and Curtin, Ryan R. and Edel, Marcus and
               Mentekidis, Yannis and Sanderson, Conrad},
  booktitle = {Proceedings of the Workshop on Systems and ML and Open Source
               Software at NeurIPS 2018},
  year      = {2018}
}

@article{curtin2017generic,
  title={A generic and fast C++ optimization framework},
  author={Curtin, Ryan R and Bhardwaj, Shikhar and Edel, Marcus and Mentekidis, Yannis},
  journal={arXiv preprint arXiv:1711.06581},
  year={2017}
}

@article{vandenberghe1996semidefinite,
  title={Semidefinite programming},
  author={Vandenberghe, Lieven and Boyd, Stephen},
  journal={SIAM Review},
  volume={38},
  number={1},
  pages={49--95},
  year={1996},
  publisher={SIAM}
}

@article{kirkpatrick1983optimization,
  title={Optimization by simulated annealing},
  author={Kirkpatrick, Scott and Gelatt, C Daniel and Vecchi, Mario P},
  journal={science},
  volume={220},
  number={4598},
  pages={671--680},
  year={1983},
  publisher={American Association for the Advancement of Science}
}

@inproceedings{montana1989training,
  title={Training Feedforward Neural Networks Using Genetic Algorithms.},
  author={Montana, David J and Davis, Lawrence},
  booktitle={IJCAI},
  volume={89},
  pages={762--767},
  year={1989}
}

@article{storn1997differential,
  title={Differential evolution--a simple and efficient heuristic for global optimization over continuous spaces},
  author={Storn, Rainer and Price, Kenneth},
  journal={Journal of global optimization},
  volume={11},
  number={4},
  pages={341--359},
  year={1997},
  publisher={Springer}
}

@article{spall1992multivariate,
  title={Multivariate stochastic approximation using a simultaneous perturbation gradient approximation},
  author={Spall, JC},
  journal={IEEE Transactions on Automatic Control},
  volume={37},
  number={3},
  pages={332--341},
  year={1992},
  publisher={IEEE}
}

@article{liu1989limited,
  title={On the limited memory BFGS method for large scale optimization},
  author={Liu, Dong C and Nocedal, Jorge},
  journal={Mathematical programming},
  volume={45},
  number={1-3},
  pages={503--528},
  year={1989},
  publisher={Springer}
}

@inproceedings{jaggi2013revisiting,
  title={Revisiting Frank-Wolfe: Projection-Free Sparse Convex Optimization},
  author={Jaggi, Martin},
  booktitle={International Conference on Machine Learning},
  pages={427--435},
  year={2013}
}

@inproceedings{Shalev-Shwartz2009,
  author    = {Shalev-Shwartz, Shai and Tewari, Ambuj},
  title     = {Stochastic Methods for L1 Regularized Loss Minimization},
  booktitle = {Proceedings of the 26th Annual International Conference on
               Machine Learning},
  series    = {ICML '09},
  year      = {2009},
  isbn = {978-1-60558-516-1}
}

@article{Hansen2001,
  author    = {Hansen, Nikolaus and Ostermeier, Andreas},
  title     = {Completely Derandomized Self-Adaptation in Evolution
               Strategies},
  journal   = {Evol. Comput.},
  volume    = {9},
  number    = {2},
  year      = {2001},
  pages     = {159--195},
  publisher = {MIT Press},
}

@inproceedings{Luo2019AdaBound,
  author    = {Luo, Liangchen and Xiong, Yuanhao and Liu, Yan and Sun, Xu},
  title     = {Adaptive Gradient Methods with Dynamic Bound of Learning
               Rate},
  booktitle = {Proceedings of the 7th International Conference on Learning
               Representations},
  month     = {May},
  year      = {2019},
  address   = {New Orleans, Louisiana}
}

@article{zeiler2012adadelta,
  title={ADADELTA: an adaptive learning rate method},
  author={Zeiler, Matthew D},
  journal={arXiv preprint arXiv:1212.5701},
  year={2012}
}

@article{duchi2011adaptive,
  author  = {Duchi, John and Hazan, Elad and Singer, Yoram},
  title   = {Adaptive subgradient methods for online learning and stochastic
             optimization},
  journal = {Journal of Machine Learning Research},
  volume  = {12},
  number  = {Jul},
  pages   = {2121--2159},
  year    = {2011}
}

@article{Kingma2014,
  author  = {Diederik P. Kingma and Jimmy Ba},
  title   = {Adam: {A} Method for Stochastic Optimization},
  journal = {CoRR},
  year    = {2014},
  url     = {http://arxiv.org/abs/1412.6980}
}

@article{reddi2019convergence,
  title={On the convergence of adam and beyond},
  author={Reddi, Sashank J and Kale, Satyen and Kumar, Sanjiv},
  journal={arXiv preprint arXiv:1904.09237},
  year={2019}
}

@article{De2017,
  title   = {Big Batch {SGD:} Automated Inference using Adaptive Batch
             Sizes},
  author  = {Soham De and Abhay Kumar Yadav and David W. Jacobs and
             Tom Goldstein},
  journal = {CoRR},
  year    = {2017},
  url     = {http://arxiv.org/abs/1610.05792},
}

@misc{1106.5730,
  author = {Mokhtari, Aryan and Eisen, Mark and Ribeiro, Alejandro},
  title  = {IQN: An Incremental Quasi-Newton Method with Local Superlinear
            Convergence Rate},
  year   = {2017},
  eprint = {arXiv:1702.00709},
}

@inproceedings{Allen-Zhu2016,
  author    = {{Allen-Zhu}, Z.},
  title     = {Katyusha: The First Direct Acceleration of Stochastic Gradient
               Methods},
  booktitle = {Proceedings of the 49th Annual ACM SIGACT Symposium on Theory
               of Computing},
  pages     = {1200--1205},
  publisher = {ACM},
  year      = {2017},
  series    = {STOC 2017},
}

@article{Zhang2019,
  author  = {Michael R. Zhang and James Lucas and Geoffrey E. Hinton and
             Jimmy Ba},
  title   = {Lookahead Optimizer: k steps forward, 1 step back},
  journal = {CoRR},
  year    = {2019},
  url     = {http://arxiv.org/abs/1907.08610}
}

@article{rumelhart1988learning,
  title   = {Learning representations by back-propagating errors},
  author  = {Rumelhart, David E. and Hinton, Geoffrey E. and
             Williams, Ronald J.},
  journal = {Cognitive Modeling},
  volume  = {5},
  number  = {3},
  pages   = {1},
  year    = {1988}
}

@techreport{Dozat2015,
  title       = {Incorporating Nesterov momentum into Adam},
  author      = {Timothy Dozat},
  institution = {Stanford University},
  address     = {Stanford},
  year        = {2015},
  url         = {https://openreview.net/pdf?id=OM0jvwB8jIp57ZJjtNEZ}
}

@techreport{Nesterov1983,
  title       = {A Method Of Solving A Convex Programming Problem With
                 Convergence Rate $O(1/k^2)$},
  author      = {Yuri Nesterov},
  institution = {Soviet Math. Dokl.},
  volume      = {27},
  year        = {1983},
}

@article{daskalakis2017training,
  author  = {Constantinos Daskalakis and Andrew Ilyas and Vasilis Syrgkanis and
             Haoyang Zeng},
  title   = {Training GANs with Optimism},
  year    = {2017},
  url     = {https://arxiv.org/abs/1711.00141},
  journal = {CoRR}
}

@inproceedings{ma2019qh,
  title={Quasi-hyperbolic momentum and Adam for deep learning},
  author={Jerry Ma and Denis Yarats},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@article{tieleman2012lecture,
  title={Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude},
  author={Tieleman, Tijmen and Hinton, Geoffrey},
  journal={COURSERA: Neural networks for machine learning},
  volume={4},
  number={2},
  pages={26--31},
  year={2012}
}

@article{Nguyen2017,
  author  = {{Nguyen}, L.~M. and {Liu}, J. and {Scheinberg},
             K. and {Tak{\'a}{\v c}}, M.},
  title   = {SARAH: A Novel Method for Machine Learning Problems Using
             Stochastic Recursive Gradient},
  journal = {ArXiv e-prints},
  url     = {https://arxiv.org/abs/1703.00102},
  year    = {2017}
}

@article{Loshchilov2016,
  title   = {{SGDR:} Stochastic Gradient Descent with Restarts},
  author  = {Ilya Loshchilov and Frank Hutter},
  journal = {CoRR},
  year    = {2016},
  url     = {https://arxiv.org/abs/1608.03983}
}

@inproceedings{Huang2017,
  title     = {Snapshot ensembles: Train 1, get m for free},
  author    = {Gao Huang and Yixuan Li and Geoff Pleiss and Zhuang Liu and
               John E. Hopcroft and Kilian Q. Weinberger},
  booktitle = {Proceedings of the International Conference on Learning
               Representations (ICLR)},
  year      = {2017},
  url       = {https://arxiv.org/abs/1704.00109}
}

@misc{Funk2015,
  author = {Simon Funk},
  title  = {RMSprop loses to SMORMS3 - Beware the Epsilon!},
  year   = {2015},
  url    = {http://sifter.org/~simon/journal/20150420.html}
}

@inproceedings{Johnson2013,
  author    = {Johnson, Rie and Zhang, Tong},
  title     = {Accelerating Stochastic Gradient Descent Using Predictive
               Variance Reduction},
  booktitle = {Proceedings of the 26th International Conference on Neural
               Information Processing Systems - Volume 1},
  series    = {NIPS'13},
  year      = {2013},
  location  = {Lake Tahoe, Nevada},
  pages     = {315--323},
  numpages  = {9},
  publisher = {Curran Associates Inc.},
}

@article{Keskar2017,
  author  = {Nitish Shirish Keskar and Richard Socher},
  title   = {Improving Generalization Performance by Switching from Adam to
             {SGD}},
  journal = {CoRR},
  volume  = {abs/1712.07628},
  year    = {2017},
  url     = {http://arxiv.org/abs/1712.07628}
}

@inproceedings{Kennedy1995,
  author    = {Kennedy, James and Eberhart, Russell C.},
  booktitle = {Proceedings of the IEEE International Conference on
               Neural Networks},
  pages     = {1942--1948},
  title     = {Particle swarm optimization},
  year      = 1995
}

@article{Koushik2016,
  author  = {Jayanth Koushik and Hiroaki Hayashi},
  title   = {Improving Stochastic Gradient Descent with Feedback},
  journal = {CoRR},
  year    = {2016},
  url     = {http://arxiv.org/abs/1611.01505}
}

@inproceedings{Zheng2017,
  author    = {Shuai Zheng and James T. Kwok},
  title     = {Follow the Moving Leader in Deep Learning},
  year      = {2017},
  booktitle = {Proceedings of the 34th International Conference on Machine Learning},
  pages     = {4110--4119},
  series    = {Proceedings of Machine Learning Research},
  publisher = {PMLR},
}

@inproceedings{recht2011hogwild,
  title={Hogwild: A lock-free approach to parallelizing stochastic gradient descent},
  author={Recht, Benjamin and Re, Christopher and Wright, Stephen and Niu, Feng},
  booktitle={Advances in neural information processing systems},
  pages={693--701},
  year={2011}
}

@misc{Schoenauer2017,
  title   = {Stochastic Gradient Descent:
             Going As Fast As Possible But Not Faster},
  author  = {Schoenauer-Sebag, Alice and Schoenauer, Marc and Sebag, Michele},
  journal = {CoRR},
  year    = {2017},
  url     = {https://arxiv.org/abs/1709.01427},
}

@article{Wu2018,
  author  = {{Wu}, X. and {Ward}, R. and {Bottou}, L.},
  title   = {WNGrad: Learn the Learning Rate in Gradient Descent},
  journal = {ArXiv e-prints},
  year    = {2018},
  url     = {https://arxiv.org/abs/1803.02865},
}

@article{burer2003nonlinear,
  title={A nonlinear programming algorithm for solving semidefinite programs via low-rank factorization},
  author={Burer, Samuel and Monteiro, Renato DC},
  journal={Mathematical Programming},
  volume={95},
  number={2},
  pages={329--357},
  year={2003},
  publisher={Springer}
}

@article{sanderson2016armadillo,
  title={Armadillo: a template-based C++ library for linear algebra},
  author={Sanderson, Conrad and Curtin, Ryan},
  journal={Journal of Open Source Software},
  volume={1},
  number={2},
  pages={26},
  year={2016},
  publisher={Journal of Open Source Software}
}



@article{mlpack2018,
  title     = {mlpack 3: a fast, flexible machine learning library},
  author    = {Curtin, Ryan R. and Edel, Marcus and Lozhnikov, Mikhail and
               Mentekidis, Yannis and Ghaisas, Sumedh and Zhang, Shangtong},
  journal   = {Journal of Open Source Software},
  volume    = {3},
  issue     = {26},
  pages     = {726},
  year      = {2018},
  doi       = {10.21105/joss.00726},
  url       = {https://doi.org/10.21105/joss.00726}
}

@misc{chollet2015keras,
  title={Keras},
  author={Chollet, Fran\c{c}ois and others},
  year={2015},
  publisher={GitHub},
  howpublished={\url{https://github.com/keras-team/keras}},
}

@article{pedregosa2011scikit,
  title={Scikit-learn: Machine learning in {Python}},
  author={Pedregosa, Fabian and Varoquaux, Ga{\"e}l and Gramfort, Alexandre and Michel, Vincent and Thirion, Bertrand and Grisel, Olivier and Blondel, Mathieu and Prettenhofer, Peter and Weiss, Ron and others},
  journal={Journal of Machine Learning Research},
  volume={12},
  number={Oct},
  pages={2825--2830},
  year={2011}
}

@misc{jones2014scipy,
  title={{SciPy}: open source scientific tools for {Python}},
  author={Jones, Eric and Oliphant, Travis and Peterson, Pearu},
  year={2014},
  note="\url{http://www.scipy.org/}",
}

@article{sonnenburg2010shogun,
  title={The {SHOGUN} machine learning toolbox},
  author={Sonnenburg, S. and R{\"a}tsch, G. and Henschel, S. and Widmer, C. and
Behr, J. and Zien, A. and de Bona, F. and
Binder, A. and Gehl, C. and Franc, V.},
  journal={Journal of Machine Learning Research},
  volume={11},
  pages={1799--1802},
  year={2010}
}

@techreport{Langford2007VW,
  title={Vowpal wabbit open source project},
  author={Langford, J. and L. Li and Strehl, A.},
  institution={Yahoo!},
  year={2007},
}

@article{mogensen2018optim,
  author  = {Mogensen, Patrick Kofod and Riseth, Asbj{\o}rn Nilsen},
  title   = {Optim: A mathematical optimization package for {Julia}},
  journal = {Journal of Open Source Software},
  year    = {2018},
  volume  = {3},
  number  = {24},
  pages   = {615},
  doi     = {10.21105/joss.00615}
}

@inproceedings{smaragdakis2000mixin,
  title={Mixin-based programming in {C++}},
  author={Smaragdakis, Yannis and Batory, Don},
  booktitle={International Symposium on Generative and Component-Based Software Engineering, Lecture Notes in Computer Science},
  volume={2177},
  pages={164--178},
  year={2000},
  organization={Springer}
}

@inproceedings{courbariaux2015training,
  title={Training deep neural networks with low precision multiplications},
  author={Courbariaux, Matthieu and Bengio, Yoshua and David, Jean-Pierre},
  booktitle={Proceedings of the 2015 International Conference on Learning
Representations (ICLR 2015)},
  year={2015}
}

@inproceedings{vanhoucke2011improving,
  title={Improving the speed of neural networks on CPUs},
  author={Vanhoucke, Vincent and Senior, Andrew and Mao, Mark Z},
  year={2011},
  booktitle={Deep Learning and Unsupervised Feature Learning Workshop at NIPS
2011}
}

@inproceedings{courbariaux2015binaryconnect,
  title={Binaryconnect: Training deep neural networks with binary weights during propagations},
  author={Courbariaux, Matthieu and Bengio, Yoshua and David, Jean-Pierre},
  booktitle={Advances in Neural Information Processing Systems 29},
  pages={3123--3131},
  year={2015}
}

@article{van2011sparse,
  title={Sparse optimization with least-squares constraints},
  author={Van den Berg, Ewout and Friedlander, Michael P},
  journal={SIAM Journal on Optimization},
  volume={21},
  number={4},
  pages={1201--1229},
  year={2011},
  publisher={SIAM}
}

@inproceedings{sanderson2018user,
    author = {Sanderson, C. and Curtin, R.R.},
    title = {A User-Friendly Hybrid Sparse Matrix Class in {C}++},
    booktitle = {Proceedings of the 2018 International Congress on Mathematical
        Software (ICMS)},
    pages = {422--430},
    publisher = {Springer},
    isbn="978-3-319-96418-8",
    year = {2018}
}


@Article{mca24030070,
AUTHOR = {Sanderson, Conrad and Curtin, Ryan},
TITLE = {Practical Sparse Matrices in C++ with Hybrid Storage and Template-Based Expression Optimisation},
JOURNAL = {Mathematical and Computational Applications},
VOLUME = {24},
YEAR = {2019},
NUMBER = {3},
ARTICLE-NUMBER = {70},
URL = {https://www.mdpi.com/2297-8747/24/3/70},
ISSN = {2297-8747},
ABSTRACT = {Despite the importance of sparse matrices in numerous fields of science, software implementations remain difficult to use for non-expert users, generally requiring the understanding of the underlying details of the chosen sparse matrix storage format. In addition, to achieve good performance, several formats may need to be used in one program, requiring explicit selection and conversion between the formats. This can be both tedious and error-prone, especially for non-expert users. Motivated by these issues, we present a user-friendly and open-source sparse matrix class for the C++ language, with a high-level application programming interface deliberately similar to the widely-used MATLAB language. This facilitates prototyping directly in C++ and aids the conversion of research code into production environments. The class internally uses two main approaches to achieve efficient execution: (i) a hybrid storage framework, which automatically and seamlessly switches between three underlying storage formats (compressed sparse column, red-black tree, coordinate list) depending on which format is best suited and/or available for specific operations, and (ii) a template-based meta-programming framework to automatically detect and optimise the execution of common expression patterns. Empirical evaluations on large sparse matrices with various densities of non-zero elements demonstrate the advantages of the hybrid storage framework and the expression optimisation mechanism.},
DOI = {10.3390/mca24030070}
}

@article{oh2004gpu,
  title={GPU implementation of neural networks},
  author={Oh, Kyoung-Su and Jung, Keechul},
  journal={Pattern Recognition},
  volume={37},
  number={6},
  pages={1311--1314},
  year={2004},
  publisher={Elsevier}
}

@inproceedings{athanasopoulos2011gpu,
  title={GPU acceleration for support vector machines},
  author={Athanasopoulos, Andreas and Dimou, Anastasios and Mezaris, Vasileios and Kompatsiaris, Ioannis},
  booktitle={Procs. 12th Inter. Workshop on Image Analysis for Multimedia Interactive Services (WIAMIS 2011), Delft, Netherlands},
  pages={17--55},
  year={2011}
}

