\subsection{Callbacks}
\label{sec:callbacks}

Many of the optimizers in {\tt ensmallen} offer the ability to monitor
and modify parts of the optimization process.
Example modifications include changing the step size,
adding custom constraints when they are violated by the current solution,
or providing custom heuristics to find and investigate feasible solutions.

In many existing toolkits, this type of functionality is provided only via
solver-specific interfaces.  For instance, the {\tt tick} statistical learning
toolkit~\cite{bacry2017tick} requires the use of a solver-specific {\tt History}.
In contrast, {\tt ensmallen} provides optimizer-independent callbacks to allow
classes to inspect and work with internal parts of the optimization process.
In particular, the callbacks allow code to be
executed regularly during an optimization session.


\subsubsection{Using Callbacks}

To use callbacks, either for optimization, tuning or logging, 
arbitrary callbacks to any optimizer can be optionally provided
to the {\tt Optimize()} function.
Figure~\ref{fig:example_prog_callbacks} contains a code snippet which
briefly demonstrates usage of the callback functionality.  Given the pre-defined
callbacks {\tt EarlyStopAtMinLoss} and {\tt ProgressBar}, the code snippet shows
not only how the {\tt MomentumSGD} optimizer can be used to find the best
coordinates but also how the callbacks can be used to control and monitor the
optimization.

Eight types of optimization callback routines are available,
as shown in Table~\ref{tab:callback_list}.
These callbacks are regularly called during the optimization process,
depending on the objective function type.
Callbacks are executed in the order that they are specified.
\TODO{description of bool value has possible inconsistency with Appendix~\ref{sec:callback_details}}
Each callback may terminate the optimization via its {\tt bool} return value,
where {\tt false} indicates that the optimization should be stopped.
By default, subsequent callbacks are not called if an earlier callback terminates
the optimization: the optimizer terminates immediately.

There are several pre-built callbacks that can be used without
needing any custom code:

\begin{itemize}
  \item {\tt EarlyStopAtMinLoss}: stops the optimization process if the loss
stops decreasing or no improvement has been made.

  \item {\tt PrintLoss}: callback that prints loss to {\tt stdout} or a
specified output stream.

  \item {\tt ProgressBar}: callback that prints a progress bar to {\tt stdout}
or a specified output stream.

  \item {\tt StoreBestCoordinates}: callback that stores the model parameter
after every epoch if the objective decreased.
\end{itemize}

Note that to use the {\tt StoreBestCoordinates} callback, the user will need to
instantiate a {\tt StoreBestCoordinates} object, and then call {\tt
BestCoordinates()} in order to recover the best coordinates found during the
optimization.  This process is detailed more in the following section.

\begin{figure}[b!]
\centering
\hrule
\vspace{1ex}
%\begin{adjustbox}{minipage=\columnwidth,scale={0.90}{0.85}}
\begin{minted}[fontsize=\small]{c++}
RosenbrockFunction f;
arma::mat coordinates = f.GetInitialPoint();

MomentumSGD optimizer(0.01, 32, 100000, 1e-5, true, MomentumUpdate(0.5));
optimizer.Optimize(f, coordinates, EarlyStopAtMinLoss(), ProgressBar());
\end{minted}
%\end{adjustbox}
\hrule
\vspace*{-0.5em}
\caption
  {
  Code snippet to demonstrate usage of the callback functionality using
pre-defined callbacks: \texttt{EarlyStopAtMinLoss} and \texttt{ProgressBar}.
{\tt EarlyStopAtMinLoss} will terminate the optimization as soon as the
objective value stars increasing, and {\tt ProgressBar} will print a progress
bar during the optimization.
  }
\label{fig:example_prog_callbacks}
\end{figure}


\begin{table}[!b]
\centering
\small
\begin{tabular}{lll}
\toprule
{\bf Function} & {\bf Description} & {\bf Function type} \\
\hline
\texttt{BeginOptimization}   & Called at the beginning of the optimization process  & {\it all} \\
\texttt{EndOptimization}     & Called at the end of the optimization process & {\it all} \\
\texttt{Evaluate}            & Called after any call to {\tt Evaluate()}            & Arbitrary, Differentiable, Partially differentiable,  \\
                             &                                                      & Arbitrary separable, Differentiable separable \\
\texttt{EvaluateConstraint}  & Called after any call to {\tt EvaluateConstraint()}  & Constrained \\
\texttt{Gradient}            & Called after any call to {\tt Gradient()}            & Differentiable, Partially differentiable \\
                             &                                                      & Differentiable separable \\
\texttt{GradientConstraint}  & Called after any call to {\tt GradientConstraint()}  & Constrained \\
\texttt{BeginEpoch}          & Called at the beginning of a pass over the data      & Differentiable separable \\
\texttt{EndEpoch}            & Called at the end of a pass over the data            & Differentiable separable \\

\bottomrule
\end{tabular}
\vspace{0.5ex}
\caption
  {
  Available callback routines, with brief descriptions.
  Optional additional arguments have been omitted for brevity.
  See {\href{http://www.ensmallen.org/docs.html}{\mbox{\tt http://www.ensmallen.org/docs.html}}} for more detailed documentation.
  }
\label{tab:callback_list}
\end{table}


\subsubsection{Custom Callbacks}

Implementing a custom callback is straightforward:
the only requirement is a class that has functions whose names are the same as the callback
functions listed in Table~\ref{tab:callback_list}.
Comprehensive documentation on the required signatures for each callback can be
found in the {\tt ensmallen} documentation at
\url{http://ensmallen.org/docs.html#callback-states}.

\TODO{still not happy with how this reads: the two {\tt Evaluate()} functions can be confusing to new users}
If a custom callback is desired to take an action after any call
to {\tt Evaluate()}, then only a {\tt CustomCallback::Evaluate()} method is required
to perform the desired action.
An example of a custom callback that 
prints a line to {\tt std::cout} every time the optimization calls
{\tt Evaluate()} is shown in Figure~\ref{fig:example_prog_callbacks_2}.
The {\tt CustomCallback} class can be used exactly like {\tt EarlyStopAtMinLoss}
in Figure~\ref{fig:example_prog_callbacks}---the only change
needed is to add {\tt CustomCallback()} to the list of arguments passed to
{\tt optimizer.Optimize()}.


\begin{figure}[!b]
\centering
\hrule
\vspace{1ex}
%\begin{adjustbox}{minipage=\columnwidth,scale={0.90}{0.85}}
\begin{minted}[fontsize=\small]{c++}
class CustomCallback
{
 public:
  template<typename OptimizerType, typename FunctionType, typename MatType>
  bool Evaluate(OptimizerType& optimizer,
                FunctionType& function,
                const MatType& coordinates,
                const double objective)
  {
    std::cout << "The optimization process called Evaluate()!" << std::endl;
    return true; // Continue the optimization process.
  }
};
\end{minted}
%\end{adjustbox}
\hrule
\vspace*{-0.5em}
\caption
  {
  An example of a custom callback.  This callback prints to {\tt std::cout}
after each time the {\tt Evaluate()} function is called by the optimizer.  The
callback always returns {\tt true}, meaning that the optimization should not be
terminated on behalf of the callback.
\TODO{possible inconsistency with Appendix~\ref{sec:callback_details}}
  }
\label{fig:example_prog_callbacks_2}
\end{figure}

\begin{figure}[b!]
\centering
\hrule
\vspace{1ex}
%\begin{adjustbox}{minipage=\columnwidth,scale={0.90}{0.85}}
\begin{minted}[fontsize=\small]{c++}
struct CustomCallback
{
  CustomCallback(double rIn) : p(rIn) {}

  template<typename OptimizerType, typename FunctionType, typename MatType>
  void StepTaken(OptimizerType& optimizer,
                 FunctionType& function,
                 MatType& coordinates)
  {
    // Multiply the step size by r (hopefully r is less than 1!).
    optimizer.StepSize() *= r;
  }

  double r;
};

RosenbrockFunction f;
arma::mat coordinates = f.GetInitialPoint();

Adam opt;
CustomCallback cb(0.9); // Instantiate the custom callback...
opt.Optimize(f, coordinates, cb); // ...and call Optimize() with that object!
\end{minted}
%\end{adjustbox}
\hrule
\vspace*{-0.5em}
\caption
  {
  Code snippet demonstrating how to add additional parameters/state to a
callback and accessing optimizer-specific parameters.
  }
\label{fig:example_prog_callbacks_parameter}
\end{figure}

If a callback class requires additional parameters or state beyond what is
passed through the predefined arguments to functions in
Table~\ref{tab:callback_list}, a user should manually create an instance of the
callback class with those additional parameters, and then pass the object to the
optimizer as a callback when {\tt Optimize()} is called.  {\tt ensmallen} does
not modify or dereference the object, so it is safe to use for this purpose.
Figure~\ref{fig:example_prog_callbacks_parameter} provides an example,
where we pass an instantiated custom callback that takes an additional
step-size decay parameter as input.
In addition, inside the {\tt StepTaken()} callback, we use the
optimizer's interface function ({\tt StepSize()}) to update the step size.
Note that  if this callback is attempted to be used with an optimizer that
did not have a {\tt StepSize()} function, compilation would fail.
As such, some care is necessary when implementing custom callbacks.

There is no performance penalty if no callbacks are used.
Figure~\ref{fig:callback_compilter_opt} shows two programs;
one explicitly without callbacks, and one with an empty callback.
The implementation of callback facility is internally
done via template metaprogramming.
In all cases, modern C++ compilers (e.g. {\tt clang-1100.0.33.16} and {\tt g++} 9.2.1)
optimized away the unused code;
the resultant machine code appears as if the callback code never existed
in the first place.
Both programs produce the exact same machine code,
indicating that there is no performance penalty if no callbacks are used.

\begin{figure}[b!]
\centering
\hrule
\vspace{1ex}
\begin{minipage}{0.47\textwidth}
\begin{minted}[fontsize=\small,stripnl=false]{c++}
struct Optimizer
{
  template<typename FT>
  void Optimize(FT& f, arma::mat& p)
  {
    f.Evaluate(p);
  }
};


int main()
{
  RosenbrockFunction rf;
  arma::mat parameters = rf.GetInitialPoint();
  Optimizer opt;
  opt.Optimize(rf, parameters);
  return 0;
}

\end{minted}
\end{minipage}
%
\hfill
\vline
\hfill
%
\begin{minipage}{0.51\textwidth}
\begin{minted}[fontsize=\small,escapeinside=||]{c++}
struct Optimizer
{
  template<typename FT, |\colorbox{yellow}{typename... CallbackType}|>
  void Optimize(FT& f, arma::mat& p, CallbackType&&... c)
  {
    |\!\!\colorbox{yellow}{Callback::BeginOptimization(*this, f, p, c...);}|
    f.Evaluate(iterate);
  }
};

int main()
{
  RosenbrockFunction rf;
  arma::mat parameters = rf.GetInitialPoint();
  Optimizer opt;
  opt.Optimize(rf, parameters);
  return 0;
}
\end{minted}
\end{minipage}
\vspace{1ex}
\hrule
%\vspace*{-0.5em}
\caption
  {
  Left panel: A C++ program that mimics the ensmallen optimizer interface
  without any callback functionality. Right panel: A corresponding C++ program
  using an empty callback routine that is automatically optimized out. Both
  programs produce the exact same machine code, resulting in no performance
  penalty if no callbacks are used.
  }
\label{fig:callback_compilter_opt}
\end{figure}

Details on the internal implementation of the callback system can be found in
Appendix~\ref{sec:callback_details}.
