\section{Overview}
\label{sec:overview}

% The primary goal of the {\tt ensmallen} library is to provide an easy-to-use
% and efficient facilities that can solve the problem $\operatorname{argmin}_x f(x)$
% for any function $f(x)$ that takes a vector or matrix input $x$.  
% To accomplish this goal, the library provides a large {set of optimizers} for optimizing
% {user-defined objective functions} in C++.  These optimizers are generic and
% flexible, meaning that they can support a wide range of use cases and
% applications.  Table~\ref{tab:comparison} contrasts the functionality supported
% by {\tt ensmallen} and other optimization toolkits.

% Many of these optimizers operate on
% specific {\it classes} of objective functions---for instance, {\tt ensmallen}
% provides many optimizers that work on differentiable functions, and so a user
% must provide both~$f(x)$ and~$f'(x)$ in such cases.
% The library allows the user to select an arbitrary type for~$x$
% (e.g., dense floating-point matrix, sparse integer matrix, etc.).

% Furthermore, in certain cases
% {\tt ensmallen} is able to infer methods that the optimizer can use beyond
% what the user has provided.  This support is internally accomplished via template
% metaprogramming and comes without runtime costs---all of the relevant work is done
% automatically at compile time.
% 
% In addition to allowing users to easily define and optimize their own objective
% functions, {\tt ensmallen} also makes it easy to implement new optimizers, which
% can then be contributed upstream and incorporated into the library.

The task of optimizing an objective function with {\tt ensmallen} is
straightforward.  The class of objective function (e.g., arbitrary, constrained,
differentiable, etc.) defines the implementation requirements.
Each objective function type has a minimal set of methods that must be implemented.
Typically this is only between one and four methods.
As an example,
to optimize an objective function $f(x)$ that is differentiable,
implementations of $f(x)$ and $f'(x)$ are required.
One of the optimizers for differentiable functions,
such as L-BFGS~\cite{liu1989limited},
can then be immediately employed.

Whenever possible, {\tt ensmallen} will automatically infer methods that are
not provided.  For instance, given a separable objective function $f(x) = \sum_i
f_i(x)$ where an implementation of $f_i(x)$ is provided (as well as the number
of such separable objectives), an implementation of $f(x)$ can be automatically
inferred.  This is done at compile-time, and so there is no additional runtime
overhead compared to a manual implementation.  C++ template metaprogramming
techniques~\cite{abrahams2004c++,alexandrescu2001modern, veldhuizen1998c++} are
internally used to produce efficient code during compilation.

Not every type of objective function can be used with every type of optimizer.
For instance, since L-BFGS is a differentiable optimizer,
it cannot be used with a non-differentiable object function type
(e.g. an arbitrary function).
When an optimizer is used with a user-provided objective function,
an internal mechanism automatically checks the requirements,
resulting in user-friendly error messages if any required methods are not detected.


\subsection{Types of Objective Functions}

In most cases, the objective function $f(x)$ has inherent attributes;
for example, as mentioned in the previous paragraphs, $f(x)$ might be differentiable.
The internal framework in {\tt ensmallen} can optionally take advantage of such attributes.
In the example of a differentiable function $f(x)$,
the user can provide an implementation of the gradient $f'(x)$,
which in turn allows a first-order optimizer to be used.  This generally leads
to significant speedups when compared to using only $f(x)$.
To allow exploitation of such attributes, the optimizers are built to work with
many types of objective functions.  The classes of objective functions
are listed below.

For details on the required signatures for each objective function type
(such as {\tt DifferentiableFunctionType}),
see the online documentation at \mbox{\url{https://ensmallen.org/docs.html}}.

\begin{itemize}
\item {\bf Arbitrary functions} ({\tt ArbitraryFunctionType}).
No assumptions are made on function $f(x)$ and only the objective
$f(x)$ can be computed for a given $x$.

\item {\bf Differentiable functions} ({\tt DifferentiableFunctionType}).
A differentiable function $f(x)$ is an arbitrary function whose gradient $f'(x)$
can be computed for a given $x$, in addition to the objective.

\item {\bf Partially differentiable functions} ({\tt
PartiallyDifferentiableFunctionType}).  A partially differentiable function
$f(x)$ is a differentiable function with the additional property that the
gradient $f'(x)$ can be decomposed along some basis $j$ such that $f_j'(x)$ is
sparse.  Often, this is used for coordinate descent algorithms (i.e., $f'(x)$
can be decomposed into $f_{1}'(x)$, $f_{2}'(x)$, etc.).

\item {\bf Arbitrary separable functions} ({\tt
ArbitrarySeparableFunctionType}).  An arbitrary separable function is an
arbitrary function $f(x)$ that can be decomposed into the sum of several
objective functions: $f(x) = \sum\nolimits_i f_i(x)$.

\item {\bf Differentiable separable functions} ({\tt
DifferentiableSeparableFunctionType}).  A differentiable separable function is a
separable arbitrary function $f(x)$ where the individual gradients $f_i'(x)$ are
also computable.

\item {\bf Categorical functions} ({\tt CategoricalFunctionType}).  A
categorical function type is an arbitrary function $f(x)$ where some (or all)
dimensions of $x$ take discrete values from a set.

\item {\bf Constrained functions} ({\tt ConstrainedFunctionType}).
A constrained function $f(x)$ is a differentiable function%
\footnote{Generally, constrained functions  do not need to be differentiable.
However, this is a requirement here, as all of the current optimizers in {\tt ensmallen}
for constrained functions require a gradient to be available.}
subject to constraints of the form $c_i(x)$; when the constraints are satisfied, $c_i(x) = 0\; \forall \; i$.
Minimizing $f(x)$ then means minimizing $f(x) + \sum_i c_i(x)$.

\item {\bf Semidefinite programs} (SDPs).  {\it (These are a subset of
constrained functions.)}  {\tt ensmallen} has special
support to make optimizing semidefinite
programs~\cite{vandenberghe1996semidefinite} straightforward.
\end{itemize}



\subsection{Pre-Built Optimizers}

For each class of the objective functions,
{\tt ensmallen} provides a set of pre-built optimizers:

\begin{itemize}
  \item {\bf For arbitrary functions:}  Simulated
annealing~\cite{kirkpatrick1983optimization}, CNE
(Conventional Neural Evolution)~\cite{montana1989training}, DE (Differential
Evolution)~\cite{storn1997differential}, PSO (Particle Swarm
Optimization)~\cite{Kennedy1995}, SPSA (Simultaneous Perturbation
Stochastic Approximation)~\cite{spall1992multivariate}.

  \item {\bf For differentiable functions:}  L-BFGS~\cite{liu1989limited},
Frank-Wolfe~\cite{jaggi2013revisiting}, gradient descent.

  \item {\bf For partially differentiable functions.}  SCD (Stochastic
Coordinate Descent)~\cite{Shalev-Shwartz2009}.

  \item {\bf For arbitrary separable functions:}  CMA-ES (Covariance Matrix
Adaptation Evolution Strategy)~\cite{Hansen2001}.

  \item {\bf For differentiable separable functions:}
AdaBound~\cite{Luo2019AdaBound},
AdaDelta~\cite{zeiler2012adadelta}, AdaGrad~\cite{duchi2011adaptive},
Adam~\cite{Kingma2014}, AdaMax~\cite{Kingma2014},
AMSBound~\cite{Luo2019AdaBound}, AMSGrad~\cite{reddi2019convergence},
Big Batch SGD~\cite{De2017}, Eve~\cite{Koushik2016}, FTML (Follow The Moving
Leader)~\cite{Zheng2017},
Hogwild!~\cite{recht2011hogwild}, IQN
(Incremental Quasi-Newton)~\cite{1106.5730}, Katyusha~\cite{Allen-Zhu2016},
Lookahead~\cite{Zhang2019}, SGD with momentum~\cite{rumelhart1988learning},
Nadam~\cite{Dozat2015},
NadaMax~\cite{Dozat2015}, SGD with Nesterov momentum~\cite{Nesterov1983},
Optimistic
Adam~\cite{daskalakis2017training}, QHAdam (Quasi-Hyperbolic
Adam)~\cite{ma2019qh}, QHSGD
(Quasi-Hyperbolic Stochastic Gradient Descent)~\cite{ma2019qh},
RMSProp~\cite{tieleman2012lecture},
SARAH/SARAH+~\cite{Nguyen2017}, stochastic gradient descent, SGDR (Stochastic Gradient
Descent with Restarts)~\cite{Loshchilov2016}, Snapshot SGDR~\cite{Huang2017},
SMORMS3~\cite{Funk2015}, SVRG (Stochastic Variance Reduced
Gradient)~\cite{Johnson2013}, SWATS~\cite{Keskar2017},
SPALeRA (Safe Parameter-wise Agnostic LEarning Rate
Adaptation)~\cite{Schoenauer2017},
WNGrad~\cite{Wu2018}.

  \item {\bf For categorical functions:}  Grid search.

  \item {\bf For constrained functions:}  Augmented Lagrangian method,
primal-dual interior point SDP solver, LRSDP (low-rank accelerated SDP
solver)~\cite{burer2003nonlinear}.
\end{itemize}


\subsection{Example Usage}
\label{sec:linreg_example}

Let us consider the problem of linear regression, where we are
given a matrix of predictors $\bm X \in \mathcal{R}^{n \times d}$ and a vector
of responses $\bm y \in \mathcal{R}^n$.  Our task is to find the best linear
model $\bm \theta \in \mathcal{R}^d$; that is, we want to find
$\bm \theta^* = \operatornamewithlimits{argmin}_{\bm\theta} f(\bm \theta)$ for
%
\begin{equation}
f(\bm \theta) = \| \bm X \bm \theta - \bm y \|^2 = (\bm X \bm \theta - \bm y)^T
(\bm X \bm \theta - \bm y).
\label{eqn:obj_lr}
\end{equation}

\noindent
From this we can derive the gradient $f'(\bm \theta)$:
%
\begin{equation}
f'(\bm \theta) = 2 \bm X^T (\bm X \bm \theta - \bm y).
\label{eqn:grad_lr}
\end{equation}

To find $\bm \theta^*$ using a differentiable
optimizer\footnote{Typically, in practice, solving a linear regression model can
be done directly by taking the psuedoinverse: $\theta^* = X^\dagger y$.  However,
the objective function is easy to describe and useful for demonstration, so we
use it in this document.}, we simply need to provide implementations of $f(\bm \theta)$ and
$f'(\bm \theta)$ according to the signatures required by the {\tt
DifferentiableFunctionType} of objective function.  For a differentiable
function, only two methods are necessary: {\tt Evaluate()} and {\tt Gradient()}.
The pre-built L-BFGS optimizer can be used to find $\bm \theta^*$.
% we just need to provide an implementation of $f(\bm \theta)$ and $f'(\bm \theta)$
% as L-BFGS requires a differentiable objective function.

Figure~\ref{fig:lr_function} shows an example implementation.
We hold {\tt X} and {\tt y} as members of the
{\tt LinearRegressionFunction class},
and {\tt theta} is used to represent $\bm \theta$.
Via the use of Armadillo~\cite{sanderson2016armadillo},
the linear algebra expressions to implement the objective function and gradient
are readable in a way that closely matches Equations~(\ref{eqn:obj_lr}) and~(\ref{eqn:grad_lr}).


% Details on how to implement and use each type of objective function 
% are omitted here for brevity.
% They can be found in the online documentation for {\tt ensmallen}
% at \mbox{\url{https://ensmallen.org/docs.html}}.
%%The details are subject to evolution over time.



\begin{figure}[b!]
\hrule
\vspace{1ex}
\centering
\begin{minted}[fontsize=\small]{c++}
#include <ensmallen.hpp>

class LinearRegressionFunction
{
 public:
  LinearRegressionFunction(const arma::mat& in_X, const arma::vec& in_y) : X(in_X), y(in_y)  { }

  double Evaluate(const arma::mat& theta)  { return (X * theta - y).t() * (X * theta - y); }

  void Gradient(const arma::mat& theta, arma::mat& gradient)  { gradient = 2 * X.t() * (X * theta - y); }

 private:
  const arma::mat& X;
  const arma::vec& y;
};

int main()
{
  arma::mat X;
  arma::vec y;
  
  // ... set the contents of X and y here ...
  
  ens::LinearRegressionFunction f(X, y);

  ens::L_BFGS optimizer; // create the optimizer with default parameters

  arma::mat theta_best(X.n_rows, 1, arma::fill::randu);  // initial starting point (uniform random values)

  optimizer.Optimize(f, theta_best);
  // at this point theta_best contains the best parameters
}
\end{minted}
\hrule
\vspace*{-0.5em}
\caption{An example implementation of an objective function class for linear
regression and usage of the L-BFGS optimizer in {\tt ensmallen}.
The online documentation for all ensmallen optimizers
is at \mbox{\url{https://ensmallen.org/docs.html}}.
The {\tt arma::mat} and {arma::vec} types are 
dense matrix and vector classes
from the Armadillo linear algebra library~\cite{sanderson2016armadillo},
with the corresponding online documentation at \mbox{\url{http://arma.sf.net/docs.html}}.
}
\label{fig:lr_function}
\end{figure}
