\section{API overview and examples}
\label{sec:api}

{\tt ensmallen} provides a {\bf set of optimizers} for optimizing {\bf
user-defined objective functions}.  These optimizers are generic and flexible,
meaning that they can support a wide range of use cases and applications.  A
primary differentiator from other toolkits is that this flexibility is provided
via template metaprogramming, which means that it comes at no runtime cost.
In addition to allowing users to easily define and optimize their own objective
functions, {\tt ensmallen} also makes it easy to implement new optimizers, which
can then be contributed back upstream and incorporated into the library.

Overall, our primary goal is to provide an easy-to-use and efficient library
that can solve the problem $\operatorname{argmin}_x f(x)$ for any function
$f(x)$ that takes a vector or matrix input $x$.  In most cases, $f(x)$ will have
some structure; one simple example might be that $f(x)$ is differentiable.
Therefore, the abstractions that we have built for {\tt ensmallen} can
optionally take advantage of this structure.  In the example of a differentiable
function $f(x)$, the user can provide an implementation of the gradient $f'(x)$,
which in turn allows a first-order optimizer to be used.  This generally leads
to significant, order-of-magnitude speedups.

To codify these structures, {\tt ensmallen}'s optimizers are made to accept
different types of objective functions.  These classes of objectives functions
are listed below.

\begin{itemize}
\item {\bf Arbitrary functions} ({\tt \small ArbitraryFunctionType}).  No
assumptions can be made on an arbitrary function $f(x)$ and only the objective
$f(x)$ can be computed for a given $x$.

\item {\bf Differentiable functions} ({\tt \small DifferentiableFunctionType}).
A differentiable function $f(x)$ is an arbitrary function whose gradient $f'(x)$
can be computed for a given $x$, in addition to the objective.

\item {\bf Partially differentiable functions} ({\tt \small
PartiallyDifferentiableFunctionType}).  A partially differentiable function
$f(x)$ is a differentiable function with the additional property that the
gradient $f'(x)$ can be decomposed along some basis $j$ such that $f_j'(x)$ is
sparse.  Often, this is used for coordinate descent algorithms (i.e., $f'(x)$
can be decomposed into $f_{x1}'(x)$, $f_{x2}'(x)$, etc.).

\item {\bf Arbitrary separable functions} ({\tt \small
ArbitrarySeparableFunctionType}).  An arbitrary separable function is an
arbitrary function $f(x)$ that can be decomposed into the sum of several
objective functions:

\begin{equation}
f(x) = \sum_i f_i(x).
\end{equation}

\item {\bf Differentiable separable functions} ({\tt \small
DifferentiableSeparableFunctionType}).  A differentiable separable function is a
separable arbitrary function $f(x)$ where the individual gradients $f_i'(x)$ are
also computable.

\item {\bf Categorical functions} ({\tt \small CategoricalFunctionType}).  A
categorical function type is an arbitrary function $f(x)$ where some (or all)
dimensions of $x$ take discrete values from a set.

\item {\bf Constrained functions} ({\tt \small ConstrainedFunctionType}).  A
constrained function $f(x)$ is a differentiable function\footnote{In general, it
is not a requirement that a constrained function is differentiable.  But we
require it here, as all {\tt ensmallen}'s current optimizers for constrained
functions require a gradient to be available.} subject to constraints of the
form $c_i(x)$; when the constraints are satisfied, $c_i(x) = 0\; \forall \; i$.
Minimizing $f(x)$ then means minimizing $f(x) + \sum_i c_i(x)$.
  \subitem {\bf Semidefinite programs} (SDPs).  {\tt ensmallen} has special
support to make optimizing semidefinite
programs~\cite{vandenberghe1996semidefinite} simple.
\end{itemize}

Details about how to implement and use each type of objective function can be
found on the {\tt ensmallen} website, at \url{https://ensmallen.org/docs.html}.

Using this straightforward abstraction framework, {\tt ensmallen} is able to
provide a wide range of optimizers:

\begin{itemize}
  \item {\bf For arbitrary functions.}  TODO

  \item {\bf For differentiable functions.}  TODO

  \item {\bf For partially differentiable functions.}  TODO

  \item {\bf For arbitrary separable functions.}  TODO

  \item {\bf For differentiable separable functions.}  TODO

  \item {\bf For categorical functions.}  TODO

  \item {\bf For constrained functions.}  TODO
\end{itemize}

Table \ref{table:comparison} compares the types of objective functions supported
by {\tt ensmallen} and other optimization toolkits.

The task of optimizing an objective function with {\tt ensmallen} is
straightforward.  The class of objective function (e.g., arbitrary, constrained,
differentiable, etc.) defines the implementation requirements.  For instance, if
a user wants to optimize some objective function $f(x)$ that is differentiable,
they merely need to provide an implementation of $f(x)$ and $f'(x)$ and then
they can immediately use one of {\tt ensmallen}'s optimizers for differentiable
functions.  That is, each objective function type has some minimal set of
methods that must be implemented.  Typically this is only between one and four
methods.

Note that not every type of objective function can be used with every type of
optimizer.  For instance, {\tt L\_BFGS} is a differentiable optimizer, and so it
cannot be used with any non-differentiable object function type (e.g. an
arbitrary function).  However, {\tt ensmallen} still allows as much flexibility
as possible via template metaprogramming:

\begin{enumerate}
  \item When an optimizer is used with a user-provided objective function,
template metaprogramming is used along with static assertions to provide
user-friendly error messages if any required methods are not detected.

  \item When possible, {\tt ensmallen} will automatically infer methods that are
not provided.  For instance, given a separable objective function where an
implementation of $f_i(x)$ is provided (as well as the number of such separable
objectives), an implementation of $f(x)$ can be inferred.  This is all done at
compile-time, and so there is no additional runtime overhead compared to a
handwritten implementation.
\end{enumerate}

To give an example, consider the example of linear regression, where we are
given a matrix of predictors $\bm X \in \mathcal{R}^{n \times d}$ and a vector
of responses $\bm y \in \mathcal{R}^n$.  Our task is to find the best linear
model $\bm \theta \in \mathcal{R}^d$; that is, we want to find $\bm \theta^* =
\operatorname{argmin} f(\bm \theta)$ for

\begin{equation}
f(\bm \theta) = \| \bm X \bm \theta - \bm y \|^2 = (\bm X \bm \theta - \bm y)^T
(\bm X \bm \theta - \bm y).
\label{eqn:obj_lr}
\end{equation}

From this we can easily derive the gradient $f'(\bm \theta)$:

\begin{equation}
f'(\bm \theta) = 2 \bm X^T (\bm X \bm \theta - \bm y).
\label{eqn:grad_lr}
\end{equation}

If we want to use {\tt ensmallen} to find $\bm \theta^*$ using a differentiable
optimizer, we simply need to provide implementations of $f(\bm \theta)$ and
$f'(\bm \theta)$ according to the signatures required by the {\tt
DifferentiableFunctionType} of objective function.  For a differentiable
function, only two methods are necessary: {\tt Evaluate()} and {\tt Gradient()}.
The introductory discussion here does not go into the full details of the
different signatures required for each objective function; for that, see the
{\tt ensmallen} documentation: \url{https://ensmallen.org/docs.html}.

Returning to our linear regression example, we could easily use {\tt ensmallen}'s
L-BFGS implementation to find $\bm \theta^*$; we just need to provide an
implementation of $f(\bm \theta)$ and $f'(\bm \theta)$ (as L-BFGS requires a
differentiable objective function).  Below is an example implementation.

\begin{minted}{c++}
class LinearRegressionFunction
{
 public:
  LinearRegressionFunction(const arma::mat& X, const arma::vec& y) : X(X), y(y)
  { }

  double Evaluate(const arma::mat& coordinates)
  {
    return (X * coordinates - y).t() * (X * coordinates - y);
  }

  void Gradient(const arma::mat& coordinates, arma::mat& gradient)
  {
    gradient = 2 * X.t() * (X * coordinates - y);
  }

  // Note that ensmallen gives us the option of only implementing *one* function
  // EvaluateWithGradient() instead, which would be more efficient in this case
  // since it can share computation between Evaluate() and Gradient()!
  //
  // (We use both Evaluate() and Gradient() here for simplicity of exposition.)

 private:
  const arma::mat& X;
  const arma::vec& y;
};
\end{minted}

In this example, we hold {\tt \small X} and {\tt \small y} as members of the
class, and {\tt \small coordinates} is used to represent $\bm \theta$.  Via the
use of Armadillo~\cite{TODO}, the linear algebra expressions to implement the
objective function and gradient are readable in a way that closely matches
Equations~\ref{eqn:obj_lr} and \ref{eqn:grad_lr}.  With {\tt \small
LinearRegressionFunction} implemented, we can easily find $\bm \theta^*$ with
the following code that uses {\tt ensmallen}'s L-BFGS optimizer:

\begin{minted}{c++}
// We assume that "X" and "y" are given.
LinearRegressionFunction f(X, y);

L_BFGS optimizer; // Create the optimizer with all default parameters.

// The theta_best matrix will hold the best model that we find after we call
// Optimize(); for now, we set it to the initial point (uniform random values).
arma::mat theta_best(X.n_rows, 1, arma::fill:randu);

optimizer.Optimize(f, theta_best);
\end{minted}

However, it's possible to do more than optimize a model that's stored as an {\tt
\small arma::mat} (dense matrix).  {\tt ensmallen} supports:

\begin{itemize}
  \item Use of types other than {\tt \small arma::mat} when calling {\tt \small
Optimize()}.  This can include integer-valued matrices, sparse matrices, or any
type whose implementation matches the Armadillo API.

  \item Callbacks, which can specify custom behavior during the optimization.
Examples include printing the loss function value at each iteration, or
terminating when a time budget is used up, or other custom user-supplied
functionality.

  \item Inference of functions not supplied by the user.  One example is that
for a differentiable function, a user might supply a {\bf joint} implementation
of the {\tt Gradient()} and {\tt Evaluate()} methods, instead of implementing
them separately.  {\tt ensmallen} can automatically infer variants of {\tt
Gradient()} and {\tt Evaluate()} when needed.
\end{itemize}

Each of the following sections will discuss how we are able to achieve the
functionality above---with no runtime overhead.
