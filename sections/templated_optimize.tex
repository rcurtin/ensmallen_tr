\section{Type-agnostic optimization}
\label{sec:templated_optimize}

% We can start by expanding on the linear regression function example to point
% out that we may want different types.

In the previous example, where we introduced the class {\tt
LinearRegressionFunction}, a drawback is clear: it only works when {\tt X}, {\tt
y}, and {\tt coordinates} ($\theta$) are of type {\tt arma::mat}---which
represents a matrix that holds {\tt double}s.

But in many applications it can be very important to specify a different
underlying storage type.  For instance, in the field of machine learning, neural
networks have been shown to be effective with low-precision floating point
representations for weights~\cite{TODO}, and even low-precision
integers~\cite{TODO} and single bits~\cite{TODO}.  In addition, many
optimization problems have parameters that are best represented as sparse
data~\cite{TODO}, which is another format that Armadillo supports~\cite{TODO}.
Even alternate representations such as data held on the GPU can be quite
important: the use of GPUs can often result in significant speedups~\cite{TODO}.

In order to handle this diverse set of needs, {\tt ensmallen} has been built in
such a way that any underlying storage type can be used to represent the
coordinates to be optimized---so long as it matches the Armadillo
API\footnote{This means that the Bandicoot GPU matrix library, found at
\href{https://gitlab.com/conradsnicta/bandicoot-code}, can be used as a drop-in
replacement once it is stable.}.

Many other libraries, such as SciPy's optimization routines, or {\tt Octave}'s,
also offer functionality that is quite generic.  However, this genericity often
comes at a runtime cost in languages like Python, since the code is not compiled
for a specific type.  In C++, we can use templates to generate code {\it
specific to the underlying matrix representation} that will have no runtime
overhead despite its flexibility.

\begin{figure}[t]
\hrule
\vspace{1ex}
\begin{minted}{c++}
class GradientDescent
{
  template<typename FunctionType, typename MatType, typename GradType = MatType>
  typename MatType::elem_type Optimize(FunctionType& function,
                                       MatType& coordinates)
  {
    // The step size is hardcoded to 0.01, and the number of iterations is 1000.
    for (size_t i = 0; i < 1000; ++i)
    {
      GradType gradient;
      function.Gradient(coordinates, gradient);

      // Take the step.
      coordinates -= 0.01 * gradient;
    }

    // Compute and return the final objective.
    return function.Evaluate(coordinates);
  }
};
\end{minted}
\hrule
\vspace*{-0.5em}
\caption{Example implementation of a gradient descent optimizer.  It is
significantly simplified from {\tt ensmallen}'s actual {\tt GradientDescent}
optimizer.}
\label{fig:gd}
\end{figure}

Consider the simple gradient descent optimizer shown in
Figure~\ref{fig:gd}\footnote{Note that much is missing from this implementation,
such as the ability to configure any parameters of the optimizer.  This is for
the sake of brevity.}.  The use of the template types {\tt FunctionType}, {\tt
MatType}, and {\tt GradType} means that at compilation time, the correct types are
substituted in for {\tt FunctionType}, {\tt MatType}, and {\tt GradType} (which
by default is set to be the same as {\tt MatType} in this code).  So long as
each type has all the methods that are used inside of {\tt Optimize()}, there
will be no compilation issue.  In addition, the code generated will be exactly
the same as if {\tt Optimize()} was written with the types specified in those
template parameters.  This means that there is no additional runtime overhead
when a different {\tt MatType} is used.  This is in contrast with languages like
Python, where any ducktyping is resolved at runtime dynamically\footnote{The
same would happen if we used C++'s {\tt virtual} keyword for virtual
inheritance.}.  In fact, for heavily-called functions, the overhead of runtime
resolution can be a noticeable and non-negligible slowdown~\cite{TODO}.
% For this citation see the "future of mlpack" document, it's some C++ TR
Thus, the ability to avoid this overhead at runtime and instead resolve at
compile time is a unique benefit to languages that have good compile-time
support for generic programming.  In Section~\ref{TODO}, we will see that this
helps {\tt ensmallen} outperform other optimization toolkits.

However, there is one important drawback of C++ that we must work around when
providing support for any {\tt MatType}, and that is the issue of compiler
errors.  The compiler may fail to substitute a given {\tt MatType} into the
code above for {\tt GradientDescent::Optimize()}; a typical reason might be that
some needed method of {\tt MatType} or {\tt FunctionType} is not available.
(Consider, for instance, if the given {\tt MatType} did not have an {\tt
operator\*()} method!)  When this happens, most C++ compilers will emit a huge
amount of error messages, with all relevant information about the attempted
template instantions.

This onslaught of error messages can be confusing and discouraging to users;
thus, we endeavor to avoid it via the use of C++ compile-time static assertions
({\tt static\_assert()}).  Specifically for checking {\tt MatType} and {\tt
GradType}, we have built some utility functions that can be used inside of any
{\tt Optimize()} method:

\begin{itemize}
  \item {\tt RequireFloatingPointType<MatType>()}: this requires that the
element type held by {\tt MatType} is either {\tt float} or {\tt double} (this
is generally needed by optimizers that use LAPACK or BLAS functionality).

  \item {\tt RequireSameInternalTypes<Mat1Type, Mat2Type>()}: this requires that
{\tt Mat1Type} and {\tt Mat2Type} use the same type to hold elements.  This can
be useful for differentiable optimizers, where we want to ensure, e.g., that a
user can't pass a {\tt MatType} that holds {\tt int}s, but a {\tt GradType} that
holds {\tt unsigned int}s.

  \item {\tt RequireDenseFloatingPointType<MatType>()}: this requires that the
element type held by {\tt MatType} is either {\tt float} or {\tt double}, and
that the representation used for storage by {\tt MatType} is dense.
\end{itemize}

At the time of writing this report, these are the only three checks that have
been needed, but it is easy to add more.  The implementation of these functions
is just a {\tt static\_assert()} that uses some underlying traits of the given
template parameters.  For example, Figure~\ref{fig:rsit} is the implementation
of {\tt RequireSameInternalTypes<...>()}.

\begin{figure}[t]
\hrule
\vspace{1ex}
\begin{minted}{c++}
/**
 * Require that the internal element type of the matrix type and gradient type
 * are the same.  A static_assert() will fail if not.
 */
template<typename MatType, typename GradType>
void RequireSameInternalTypes()
{
#ifndef ENS_DISABLE_TYPE_CHECKS
  static_assert(std::is_same<typename MatType::elem_type,
                             typename GradType::elem_type>::value,
      "The internal element types of the given MatType and GradType must be "
      "identical, or it is not known to work!  If you would like to try "
      "anyway, set the preprocessor macro ENS_DISABLE_TYPE_CHECKS before "
      "including ensmallen.hpp.  However, you get to pick up all the pieces if "
      "there is a failure!");
#endif
}
\end{minted}
\hrule
\vspace*{-0.5em}
\caption{Implementation of {\tt RequireSameInternalTypes()} from internal {\tt
ensmallen} code.}
\label{fig:rsit}
\end{figure}

Note that for users who would like to continue despite the checks failing, they
simply need to define the macro {\tt ENS\_DISABLE\_TYPE\_CHECKS} in their code
before the line {\tt \#include <ensmallen.hpp>}.
